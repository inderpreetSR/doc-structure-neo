<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Pipeline 2: Git-Driven Change Detection</title>
  <meta name="description" content="Pipeline 2: Detect git changes, resolve dependencies, and selectively regenerate documentation.">
  <link rel="stylesheet" href="assets/style.css">
</head>
<body>

  <a class="skip-link" href="#main">Skip to content</a>

  <header>
    <nav class="top-nav" aria-label="Primary">
      <span class="logo">DocPipelines</span>
      <a href="index.html">Home</a>
      <a href="1-code-aware.html">Code-Aware</a>
      <a href="2-git-driven.html" class="active" aria-current="page">Git-Driven</a>
      <a href="3-rag-knowledge.html">RAG</a>
      <a href="4-living-docs.html">Living Docs</a>
      <a href="5-multi-source.html">Multi-Source</a>
      <a href="6-full-stack.html">Full-Stack</a>
    </nav>
  </header>

  <main id="main">
    <section class="hero">
      <h1>Git-Driven Change Detection</h1>
      <p>Detect changed files via git diff, build a dependency graph, and selectively regenerate only the documentation that needs updating.</p>
    </section>

    <section class="page-content">

    <h2>Architecture</h2>
    <div class="flow">
      <span class="step">Git Diff</span>
      <span class="arrow">&rarr;</span>
      <span class="step">Changed Files</span>
      <span class="arrow">&rarr;</span>
      <span class="step">Dependency Graph</span>
      <span class="arrow">&rarr;</span>
      <span class="step">Affected Modules</span>
      <span class="arrow">&rarr;</span>
      <span class="step">Selective Re-Gen</span>
      <span class="arrow">&rarr;</span>
      <span class="step">Deploy</span>
    </div>

    <h2>How It Works</h2>
    <ol>
      <li><strong>Diff</strong> &mdash; Run <code>git diff --name-only HEAD~1</code> to find files changed in the last commit</li>
      <li><strong>Graph</strong> &mdash; Parse import statements to build a dependency graph of all modules</li>
      <li><strong>Resolve</strong> &mdash; Walk the graph to find all modules affected by the changed files (direct + transitive)</li>
      <li><strong>Regenerate</strong> &mdash; Only regenerate documentation for affected modules</li>
      <li><strong>Deploy</strong> &mdash; Push updated docs to the static site</li>
    </ol>

    <h2>Pipeline Script</h2>
    <pre><code># pipelines/2-git-driven/pipeline.py
# Run: python pipeline.py --repo ./your-repo --output ./docs

import subprocess, re, os, json, argparse
from pathlib import Path
from collections import defaultdict
from datetime import datetime

class GitDrivenDocPipeline:
    """Detects git changes and selectively regenerates docs."""

    def __init__(self, repo_dir, output_dir, base_ref='HEAD~1'):
        self.repo_dir = Path(repo_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.base_ref = base_ref
        self.dep_graph = defaultdict(set)   # module -> set of dependents
        self.import_map = defaultdict(set)  # module -> set of imports

    def get_changed_files(self):
        """Get list of changed files from git diff."""
        result = subprocess.run(
            ['git', 'diff', '--name-only', self.base_ref],
            cwd=self.repo_dir, capture_output=True, text=True
        )
        files = [f.strip() for f in result.stdout.strip().split('\n') if f.strip()]
        print(f"[diff]  {len(files)} files changed since {self.base_ref}")
        return files

    def build_dependency_graph(self):
        """Parse imports to build a dependency graph."""
        py_files = list(self.repo_dir.rglob('*.py'))
        import_pattern = re.compile(
            r'^(?:from\s+([\w.]+)\s+import|import\s+([\w.]+))', re.MULTILINE
        )
        for filepath in py_files:
            module = str(filepath.relative_to(self.repo_dir)).replace(os.sep, '.').rstrip('.py')
            try:
                source = filepath.read_text(encoding='utf-8')
            except Exception:
                continue
            for match in import_pattern.finditer(source):
                imported = match.group(1) or match.group(2)
                self.import_map[module].add(imported)
                self.dep_graph[imported].add(module)  # imported -> depended on by module

        print(f"[graph] Built dependency graph: {len(self.dep_graph)} modules")
        return self.dep_graph

    def resolve_affected(self, changed_files):
        """Resolve all affected modules (direct + transitive dependents)."""
        changed_modules = set()
        for f in changed_files:
            if f.endswith('.py'):
                mod = f.replace(os.sep, '.').rstrip('.py')
                changed_modules.add(mod)

        affected = set(changed_modules)
        queue = list(changed_modules)
        while queue:
            current = queue.pop(0)
            for dependent in self.dep_graph.get(current, set()):
                if dependent not in affected:
                    affected.add(dependent)
                    queue.append(dependent)

        print(f"[resolve] {len(changed_modules)} changed -> {len(affected)} affected modules")
        return affected

    def regenerate_docs(self, affected_modules):
        """Regenerate documentation only for affected modules."""
        regenerated = []
        for module in sorted(affected_modules):
            mod_path = self.repo_dir / module.replace('.', os.sep)
            # Try .py extension
            candidates = [mod_path.with_suffix('.py'), mod_path / '__init__.py']
            for candidate in candidates:
                if candidate.exists():
                    doc_content = self._generate_doc(candidate, module)
                    out_path = self.output_dir / f"{module.replace('.', '_')}.md"
                    out_path.write_text(doc_content, encoding='utf-8')
                    regenerated.append(module)
                    print(f"[regen] {module}")
                    break
        return regenerated

    def _generate_doc(self, filepath, module_name):
        """Generate a Markdown doc for a module."""
        source = filepath.read_text(encoding='utf-8')
        line_count = len(source.splitlines())
        imports = self.import_map.get(module_name, set())
        dependents = self.dep_graph.get(module_name, set())

        md = f"# {module_name}\n\n"
        md += f"*Auto-generated on {datetime.now().strftime('%Y-%m-%d %H:%M')}*\n\n"
        md += f"**Source:** `{filepath.relative_to(self.repo_dir)}`  \n"
        md += f"**Lines:** {line_count}  \n\n"
        if imports:
            md += f"**Imports:** {', '.join(f'`{i}`' for i in sorted(imports))}\n\n"
        if dependents:
            md += f"**Used by:** {', '.join(f'`{d}`' for d in sorted(dependents))}\n\n"
        md += "---\n\n"
        md += "```python\n" + source[:2000] + "\n```\n"
        return md

    def run(self):
        """Execute the full pipeline."""
        changed = self.get_changed_files()
        if not changed:
            print("[done] No changes detected, nothing to regenerate.")
            return
        self.build_dependency_graph()
        affected = self.resolve_affected(changed)
        regenerated = self.regenerate_docs(affected)

        report = {
            'timestamp': datetime.now().isoformat(),
            'base_ref': self.base_ref,
            'changed_files': changed,
            'affected_modules': list(affected),
            'regenerated': regenerated
        }
        report_path = self.output_dir / 'build-report.json'
        report_path.write_text(json.dumps(report, indent=2))
        print(f"\n[done] Regenerated {len(regenerated)} docs")
        print(f"[done] Report saved to {report_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Git-Driven Doc Pipeline')
    parser.add_argument('--repo', required=True, help='Git repository path')
    parser.add_argument('--output', default='./docs', help='Output directory')
    parser.add_argument('--base-ref', default='HEAD~1', help='Git base reference')
    args = parser.parse_args()
    pipeline = GitDrivenDocPipeline(args.repo, args.output, args.base_ref)
    pipeline.run()
</code></pre>

    <h2>CI/CD Integration</h2>
    <p>Add this to your <code>.github/workflows/docs.yml</code>:</p>
    <pre><code>name: Update Docs
on: [push]
jobs:
  docs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 2 }
      - uses: actions/setup-python@v5
        with: { python-version: '3.12' }
      - run: python pipelines/2-git-driven/pipeline.py --repo . --output docs/
      - uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs</code></pre>

    <h2>Key Features</h2>
    <ul>
      <li>Incremental builds &mdash; only regenerate what changed</li>
      <li>Transitive dependency resolution via import graph</li>
      <li>Build reports in JSON for audit trails</li>
      <li>Direct CI/CD integration with GitHub Actions</li>
      <li>Works with any git hosting provider</li>
    </ul>

    </section>
  </main>

  <footer>
    <a href="index.html" class="btn btn-outline" style="margin-bottom:1rem;">Back to All Pipelines</a>
    <p>&copy; 2026 Intelligent Documentation Pipelines</p>
  </footer>

</body>
</html>
